import { searchTopK } from "./runtime";

export function kidsTemplateAnswer(question: string, chunksText: string) {
  const resumo = chunksText.trim() ? chunksText.trim().slice(0, 550) : "";

  if (!resumo) {
    return (
      "Hummâ€¦ eu nÃ£o achei isso na minha biblioteca ainda ðŸª²âœ¨\n\n" +
      "1) ExplicaÃ§Ã£o: Eu nÃ£o tenho certeza, mas posso te ajudar a procurar com um professor ou responsÃ¡vel.\n" +
      "2) Exemplo: VocÃª pode perguntar: â€œVocÃª pode me explicar isso com um exemplo?â€\n" +
      "3) Sua vez: Qual matÃ©ria Ã©? (MatemÃ¡tica, PortuguÃªs ou CiÃªncias)"
    );
  }

  return (
    "Certo! Vamos aprender juntinhos ðŸª²âœ¨\n\n" +
    "1) ExplicaÃ§Ã£o bem simples:\n" +
    resumo.split("\n").slice(0, 3).join("\n") +
    "\n\n2) Um exemplo bem fÃ¡cil:\n" +
    (resumo.split("\n").find((l) => l.toLowerCase().includes("exemplo")) ??
      "Exemplo: vamos fazer um passo por vez!") +
    "\n\n3) Sua vez:\n" +
    "VocÃª consegue me dizer com suas palavras o que entendeu?"
  );
}

export async function answerWithAutoMode(message: string) {
  const chunks = await searchTopK(message, 4);
  const contexto = chunks
    .map((c, i) => `Trecho ${i + 1} (${c.source})\n${c.text}`)
    .join("\n\n");

  // tenta Ollama (se existir). Se falhar, cai no rag-only.
  try {
    const { ChatOllama } = await import(
      "@langchain/community/chat_models/ollama"
    );
    const model = new ChatOllama({ model: "llama3.1", temperature: 0.4 });

    const prompt = `
VocÃª Ã© o Vagalume Professor ðŸª²âœ¨ para crianÃ§as de 7 a 11 anos (1Âº ao 5Âº ano).
Fale em portuguÃªs do Brasil.
Responda SEMPRE em 3 partes:
1) ExplicaÃ§Ã£o simples (mÃ¡x 4 linhas)
2) Exemplo fÃ¡cil (mÃ¡x 3 linhas)
3) Pergunta para a crianÃ§a tentar (1 linha)
Se nÃ£o estiver no contexto, diga com carinho que nÃ£o tem certeza.

CONTEXTO (biblioteca):
${contexto}

PERGUNTA:
${message}
`.trim();

    const resp = await model.invoke(prompt);
    return { answer: String(resp.content ?? ""), sources: chunks };
  } catch {
    const answer = kidsTemplateAnswer(
      message,
      chunks.map((c) => c.text).join("\n\n")
    );
    return { answer, sources: chunks };
  }
}
