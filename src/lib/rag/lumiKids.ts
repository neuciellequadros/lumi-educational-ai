import { searchTopKEmbeddings } from "./embStore";

export function kidsTemplateAnswer(chunksText: string) {
  const resumo = chunksText.trim() ? chunksText.trim().slice(0, 600) : "";
  if (!resumo) {
    return (
      "Opa! Eu nÃ£o achei isso na minha biblioteca ainda ðŸª²ðŸŸ¡âœ¨\n\n" +
      "1) ExplicaÃ§Ã£o: Eu nÃ£o tenho certezaâ€¦ mas posso te ajudar a procurar com um adulto.\n" +
      "2) Exemplo: Tente me dizer qual matÃ©ria Ã© (MatemÃ¡tica, PortuguÃªs ou CiÃªncias).\n" +
      "3) Sua vez: Qual sÃ©rie vocÃª estÃ¡? (1Âº ao 5Âº)"
    );
  }

  const exemploLinha =
    resumo.split("\n").find((l) => l.toLowerCase().includes("exemplo")) ??
    "Exemplo: vamos fazer juntinhos um passo por vez!";

  return (
    "Oba! Vamos aprender no Mundo do Vagalume ðŸª²ðŸŸ¡âœ¨\n\n" +
    "1) ExplicaÃ§Ã£o bem simples:\n" +
    resumo.split("\n").slice(0, 3).join("\n") +
    "\n\n2) Um exemplo bem fÃ¡cil:\n" +
    exemploLinha +
    "\n\n3) Sua vez:\n" +
    "VocÃª quer tentar um exercÃ­cio rapidinho?"
  );
}

export async function answerWithAutoMode(message: string) {
  const chunks = await searchTopKEmbeddings(message, 4);
  const contexto = chunks
    .map((c, i) => `Trecho ${i + 1} (${c.source})\n${c.text}`)
    .join("\n\n");

  try {
    const { ChatOllama } = await import(
      "@langchain/community/chat_models/ollama"
    );
    const model = new ChatOllama({
      model: process.env.OLLAMA_LLM_MODEL || "llama3.1",
      temperature: 0.4,
    });

    const prompt = `
VocÃª Ã© o Vagalume Professor ðŸª²ðŸŸ¡âœ¨, para crianÃ§as de 7 a 11 anos (1Âº ao 5Âº ano).
Fale em portuguÃªs do Brasil.
Responda SEMPRE em 3 partes:
1) ExplicaÃ§Ã£o simples (mÃ¡x 4 linhas)
2) Exemplo fÃ¡cil (mÃ¡x 3 linhas)
3) Pergunta para a crianÃ§a tentar (1 linha)
Se nÃ£o estiver no contexto, diga com carinho que nÃ£o tem certeza.

CONTEXTO (biblioteca):
${contexto}

PERGUNTA:
${message}
`.trim();

    const resp = await model.invoke(prompt);
    return { answer: String(resp.content ?? ""), sources: chunks };
  } catch {
    const answer = kidsTemplateAnswer(chunks.map((c) => c.text).join("\n\n"));
    return { answer, sources: chunks };
  }
}
